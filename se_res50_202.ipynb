{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "mult = 1 # channel multiplier for transposed convolutions\n",
    "folds_to_train = range(n_splits)\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 202\n",
    "max_crop_sz = int(sz * 0.9)\n",
    "\n",
    "trn_tfms = albumentations.Compose([\n",
    "    albumentations.HorizontalFlip(),\n",
    "    albumentations.RandomSizedCrop((max_crop_sz, max_crop_sz), sz, sz, interpolation=1, p=0.5),\n",
    "    albumentations.IAAAffine(rotate=10, p=0.5, mode='edge'),\n",
    "    albumentations.Blur()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tfms = albumentations.Compose([\n",
    "    albumentations.PadIfNeeded(256, 256)\n",
    "])\n",
    "\n",
    "def get_data_bunch(sz=128, bs=64, part=0, trn_tfms=trn_tfms):\n",
    "    trn_ds = FilesDataset(PATH/TRAIN_DN, sz, take_idxs=trn_parts[part], tfms=albumentations.Compose([trn_tfms, base_tfms]))\n",
    "    val_ds = FilesDataset(PATH/TRAIN_DN, sz, take_idxs=val_parts[part], tfms=base_tfms)\n",
    "    tst_ds = FilesDataset(PATH/TEST_DN, sz, tfms=base_tfms)\n",
    "    \n",
    "    trn_dl = DataLoader(trn_ds, bs, True, num_workers=11, pin_memory=True)\n",
    "    val_dl = DataLoader(val_ds, bs, False, num_workers=11, pin_memory=True)\n",
    "    tst_dl = DataLoader(tst_ds, bs, False, num_workers=11, pin_memory=True)\n",
    "    \n",
    "    trn_dl, val_dl, tst_dl = map(lambda ts: DeviceDataLoader(*ts), zip([trn_dl, val_dl, tst_dl], [default_device] * 3) )\n",
    "    return DataBunch(trn_dl, val_dl, tst_dl, default_device)\n",
    "\n",
    "def predict(model, dl, flip=True):\n",
    "    model.eval()\n",
    "    preds = [torch.sigmoid(model(xb)).detach().cpu().numpy()[:, 27:-27, 27:-27] for xb, yb in dl]\n",
    "    preds = np.concatenate(preds)\n",
    "    if not flip: return preds\n",
    "    flipped_preds = np.concatenate([torch.sigmoid(model(torch.flip(xb, [3]))).detach().cpu().numpy()[:, 27:-27, 27:-27] for xb, yb in dl])\n",
    "    preds = (preds + flipped_preds[:,:,::-1]) / 2\n",
    "    return preds\n",
    "\n",
    "def predict_with_TTA(model, dl, upside_down=True):\n",
    "    model.eval()\n",
    "    \n",
    "    preds = np.concatenate([torch.sigmoid(model(xb)).detach().cpu().numpy()[:, 27:-27, 27:-27] for xb, yb in dl])\n",
    "    if upside_down: preds_upside_down = np.concatenate([torch.sigmoid(model(torch.flip(xb, [2]))).detach().cpu().numpy()[:, 27:-27, 27:-27] for xb, yb in dl])\n",
    "    \n",
    "    flipped_preds = np.concatenate([torch.sigmoid(model(torch.flip(xb, [3]))).detach().cpu().numpy()[:, 27:-27, 27:-27] for xb, yb in dl])\n",
    "    if upside_down: flipped_preds_upside_down = np.concatenate([torch.sigmoid(model(torch.flip(xb, [1, 3]))).detach().cpu().numpy()[:, 27:-27, 27:-27] for xb, yb in dl])\n",
    "    \n",
    "    preds = (preds + flipped_preds[:,:,::-1]) / 2\n",
    "    if upside_down: preds = 0.5 * preds + (preds_upside_down[:,::-1,:] + flipped_preds_upside_down[:,::-1,::-1]) / 4 \n",
    "    return preds\n",
    "\n",
    "def predict_with_targs_and_TTA(model, dl, upside_down=True):\n",
    "    preds = predict_with_TTA(model, dl, upside_down)\n",
    "    targs = np.concatenate([yb.detach().cpu().numpy()[:, 27:-27, 27:-27] for xb, yb in dl])\n",
    "    return preds, targs\n",
    "\n",
    "def accuracy_no_pad(preds, targs):\n",
    "    return accuracy_thresh(preds[:, 27:-27, 27:-27], targs[:, 27:-27, 27:-27])\n",
    "\n",
    "def dice_no_pad(preds, targs):\n",
    "    return dice(preds[:, 27:-27, 27:-27], targs[:, 27:-27, 27:-27])\n",
    "\n",
    "def iou_pytorch(out, yb):\n",
    "    preds = out > 0\n",
    "    return torch.tensor(iou_metric(yb.cpu().numpy()[:, 27:-27, 27:-27], preds.cpu().numpy()[:, 27:-27, 27:-27]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, k, stride=2, padding=(k-2)//2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        self.out_channels = n_out\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "    \n",
    "class UnetSE_res50(nn.Module):        \n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in range(4)]\n",
    "        self.up1 = UnetBlock(2048,1024,768)\n",
    "        self.up2 = UnetBlock(768,512,320)\n",
    "        self.up3 = UnetBlock(320,256 + 64,160)\n",
    "        self.up4 = nn.ConvTranspose2d(160, 48, k, stride=2, padding=(k-2)//2)\n",
    "        self.up4_bn = nn.BatchNorm2d(48)\n",
    "        self.up5 = UnetBlock(48,3,32)\n",
    "        \n",
    "        self.se1 = scSELayer(self.up1.out_channels)\n",
    "        self.se2 = scSELayer(self.up2.out_channels)\n",
    "        self.se3 = scSELayer(self.up3.out_channels)\n",
    "        self.se4 = scSELayer(48)\n",
    "        self.se5 = scSELayer(self.up5.out_channels)\n",
    "        \n",
    "        self.se_feat1 = scSELayer(256 + 64)\n",
    "        self.se_feat2 = scSELayer(512)\n",
    "        self.se_feat3 = scSELayer(1024)\n",
    "        \n",
    "        self.hc1 = HCBlock(self.up1.out_channels)\n",
    "        self.hc2 = HCBlock(self.up2.out_channels)\n",
    "        self.hc3 = HCBlock(self.up3.out_channels)\n",
    "        self.hc4 = HCBlock(48)\n",
    "        \n",
    "        self.hc_comb = nn.Conv2d(64, 8, 3, padding=1)\n",
    "        self.hc_bn = nn.BatchNorm2d(8)\n",
    "        \n",
    "        self.up6 = nn.ConvTranspose2d(32 + 8, 1, 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        inp = x\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.se_feat3(self.sfs[3].features))\n",
    "        x = self.se1(x)\n",
    "        hc1 = self.hc1(x)\n",
    "        \n",
    "        x = self.up2(x, self.se_feat2(self.sfs[2].features))\n",
    "        x = self.se2(x)\n",
    "        hc2 = self.hc2(x)\n",
    "        \n",
    "        feats = torch.cat((self.sfs[0].features, self.sfs[1].features), dim=1)\n",
    "        x = self.up3(x, self.se_feat1(feats))\n",
    "        x = self.se3(x)\n",
    "        hc3 = self.hc3(x)\n",
    "        \n",
    "        x = F.relu(self.up4_bn(self.up4(x)))\n",
    "        x = self.se4(x)\n",
    "        hc4 = self.hc4(x)\n",
    "        \n",
    "        x = self.up5(x, inp)\n",
    "        x = self.se5(x)\n",
    "        \n",
    "        hc = self.hc_comb(torch.cat((hc1, hc2, hc3, hc4), dim=1))\n",
    "        hc = self.hc_bn(F.relu(hc))\n",
    "        x = torch.cat((x, hc), dim=1)\n",
    "        x = self.up6(x)\n",
    "        return x[:,0]\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(db):\n",
    "    se_res50 = nn.Sequential(*list(pretrainedmodels.se_resnext50_32x4d().children())[:-2])\n",
    "    m = UnetSE_res50(se_res50)\n",
    "    m.cuda(default_device)\n",
    "    learn = Learner(db, m, true_wd=True, loss_fn=bce_loss, opt_fn=lambda x: optim.SGD(x))\n",
    "#     learn = Learner(db, m, true_wd=True, loss_fn=bce_loss, opt_fn=AdamW)\n",
    "    learn.metrics = [accuracy_no_pad, dice_no_pad, iou_pytorch]\n",
    "    learn.callbacks = [SaveBest()]\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Starting to train fold 0 ###\n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.292015    0.284441    0.893400         0.765132     0.479095   \n",
      "1      0.253959    0.238934    0.916907         0.809451     0.600489   \n",
      "2      0.239984    0.215250    0.921299         0.811561     0.673594   \n",
      "3      0.225915    0.231175    0.908503         0.796814     0.617237   \n",
      "4      0.199795    0.196116    0.929191         0.831452     0.677384   \n",
      "7      0.177344    0.176710    0.937149         0.854180     0.726161   \n",
      "8      0.166554    0.172456    0.937998         0.858530     0.722127   \n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.155714    0.167249    0.938719         0.860583     0.729584   \n",
      "1      0.167333    0.171031    0.932695         0.839854     0.712225   \n",
      "2      0.153857    0.157989    0.941205         0.862606     0.738509   \n",
      "3      0.157417    0.166514    0.937934         0.852908     0.739364   \n",
      "4      0.143205    0.151390    0.943401         0.867002     0.750978   \n",
      "5      0.131253    0.168257    0.941319         0.862228     0.757946   \n",
      "6      0.133674    0.158805    0.942893         0.866364     0.762958   \n",
      "7      0.126721    0.148028    0.947843         0.876641     0.747922   \n",
      "8      0.138315    0.188035    0.932895         0.845118     0.755379   \n",
      "9      0.128424    0.146780    0.950260         0.890804     0.767848   \n",
      "10     0.112337    0.141521    0.949131         0.883416     0.776895   \n",
      "11     0.109756    0.153000    0.946486         0.873967     0.785941   \n",
      "12     0.116133    0.146860    0.946626         0.877095     0.780196   \n",
      "13     0.089357    0.160985    0.945255         0.883297     0.791809   \n",
      "14     0.105057    0.150279    0.950656         0.893474     0.787041   \n",
      "15     0.099529    0.157149    0.944309         0.876997     0.790220   \n",
      "16     0.095911    0.155106    0.945777         0.875561     0.789731   \n",
      "17     0.099136    0.167212    0.948457         0.885574     0.778362   \n",
      "18     0.099961    0.157255    0.944060         0.871349     0.787042   \n",
      "19     0.081766    0.176446    0.947885         0.885577     0.796944   \n",
      "20     0.079087    0.180388    0.939074         0.861070     0.779095   \n",
      "21     0.088964    0.174875    0.944975         0.869098     0.784352   \n",
      "22     0.093201    0.188123    0.938303         0.864881     0.787408   \n",
      "23     0.071287    0.157214    0.949530         0.883729     0.797799   \n",
      "24     0.065250    0.189069    0.940366         0.859032     0.788020   \n",
      "26     0.067284    0.191706    0.934290         0.854295     0.781051   \n",
      "27     0.069542    0.191492    0.945472         0.872498     0.787897   \n",
      "28     0.065671    0.194412    0.935618         0.857561     0.783007   \n",
      "29     0.061671    0.182115    0.946705         0.874163     0.804768   \n",
      "30     0.050061    0.187387    0.948183         0.882920     0.805379   \n",
      "31     0.046547    0.186785    0.946764         0.879266     0.806724   \n",
      "32     0.046259    0.179061    0.947290         0.877462     0.807946   \n",
      "33     0.042452    0.193816    0.942934         0.866440     0.799511   \n",
      "34     0.040078    0.178702    0.948763         0.884821     0.811002   \n",
      "35     0.038381    0.190285    0.947738         0.878362     0.808069   \n",
      "36     0.041213    0.188039    0.948823         0.885045     0.812103   \n",
      "37     0.037077    0.192447    0.949498         0.884476     0.807213   \n",
      "38     0.037597    0.191938    0.950120         0.886260     0.813814   \n",
      "39     0.040173    0.185047    0.949884         0.885731     0.810391   \n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.325330    0.575791    0.944784         0.879410     0.800122   \n",
      "1      0.309089    0.462943    0.948357         0.884023     0.807335   \n",
      "2      0.305901    0.428719    0.948989         0.884431     0.816381   \n",
      "3      0.295306    0.437584    0.949804         0.890192     0.807457   \n",
      "4      0.334754    0.455477    0.944474         0.870454     0.804401   \n",
      "5      0.250826    0.400610    0.948198         0.879118     0.817848   \n",
      "6      0.244521    0.414730    0.938663         0.850811     0.816381   \n",
      "7      0.266749    0.407788    0.946682         0.874690     0.803178   \n",
      "8      0.262035    0.389851    0.945512         0.881284     0.821760   \n",
      "9      0.253739    0.376413    0.947762         0.884285     0.817115   \n",
      "10     0.258653    0.412647    0.929002         0.846904     0.805257   \n",
      "11     0.277562    0.385947    0.945969         0.871272     0.816870   \n",
      "12     0.249800    0.351262    0.946518         0.875257     0.826650   \n",
      "13     0.241511    0.355207    0.948498         0.877609     0.821883   \n",
      "14     0.241972    0.386985    0.945871         0.875325     0.814914   \n",
      "15     0.237343    0.359687    0.948455         0.885546     0.822005   \n",
      "16     0.216714    0.351854    0.949297         0.888700     0.824205   \n",
      "17     0.235534    0.325374    0.948721         0.878027     0.831540   \n",
      "18     0.214601    0.354422    0.945343         0.868226     0.823716   \n",
      "19     0.224110    0.356806    0.941876         0.861074     0.823350   \n",
      "20     0.205064    0.319595    0.945346         0.868816     0.826895   \n",
      "21     0.215585    0.331457    0.946601         0.870909     0.820782   \n",
      "22     0.195276    0.322651    0.948288         0.877014     0.832885   \n",
      "23     0.185789    0.334181    0.947137         0.879803     0.820171   \n",
      "24     0.177779    0.341439    0.946372         0.874273     0.833007   \n",
      "25     0.191182    0.344816    0.936285         0.849449     0.819927   \n",
      "26     0.181903    0.334231    0.951909         0.885924     0.830685   \n",
      "27     0.171758    0.323580    0.947721         0.877991     0.836430   \n",
      "28     0.182939    0.331284    0.947289         0.875669     0.833618   \n",
      "29     0.171292    0.324126    0.948196         0.877070     0.838264   \n",
      "30     0.156041    0.308779    0.950366         0.889621     0.835208   \n",
      "31     0.162099    0.305679    0.951452         0.891638     0.841320   \n",
      "32     0.144902    0.311621    0.951814         0.887959     0.839853   \n",
      "33     0.163073    0.300463    0.952142         0.888757     0.846088   \n",
      "34     0.151513    0.308357    0.948723         0.881884     0.842054   \n",
      "35     0.142947    0.305185    0.951276         0.886874     0.843276   \n",
      "36     0.140051    0.304774    0.952123         0.889238     0.844743   \n",
      "37     0.131431    0.302889    0.950653         0.884899     0.846699   \n",
      "38     0.146138    0.303541    0.951490         0.885731     0.846455   \n",
      "39     0.137423    0.301352    0.950561         0.886078     0.843521   \n",
      "### Starting to train fold 1 ###\n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.294580    0.234407    0.913057         0.810459     0.521111   \n",
      "1      0.245567    0.219932    0.919378         0.819140     0.616296   \n",
      "2      0.235421    0.211660    0.923952         0.823897     0.670494   \n",
      "3      0.235919    0.196107    0.925795         0.845964     0.603704   \n",
      "4      0.224536    0.182928    0.932168         0.839903     0.672839   \n",
      "5      0.237791    0.218067    0.911865         0.833663     0.583333   \n",
      "6      0.200371    0.163719    0.938459         0.863160     0.692716   \n",
      "7      0.181539    0.163783    0.938530         0.859340     0.709012   \n",
      "8      0.169822    0.174130    0.929733         0.853765     0.690247   \n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.164974    0.175086    0.928671         0.858031     0.689383   \n",
      "1      0.162276    0.158716    0.939408         0.873220     0.713210   \n",
      "2      0.150611    0.151103    0.944368         0.884316     0.719506   \n",
      "3      0.158648    0.142422    0.946569         0.887079     0.753951   \n",
      "4      0.156503    0.139418    0.947224         0.882609     0.756914   \n",
      "5      0.135285    0.146379    0.946418         0.881912     0.762840   \n",
      "6      0.130589    0.132504    0.952863         0.897127     0.769753   \n",
      "7      0.162361    0.147204    0.945899         0.885279     0.732099   \n",
      "8      0.121126    0.147088    0.945250         0.894371     0.766296   \n",
      "9      0.115959    0.134650    0.954911         0.905174     0.778889   \n",
      "10     0.130437    0.130636    0.948220         0.892444     0.770123   \n",
      "11     0.113937    0.194628    0.924362         0.847020     0.738518   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12     0.101597    0.132654    0.950968         0.897303     0.783827   \n",
      "13     0.096382    0.129984    0.951010         0.900368     0.782839   \n",
      "14     0.099245    0.148545    0.944296         0.884735     0.763704   \n",
      "15     0.099558    0.134252    0.950512         0.900564     0.780617   \n",
      "16     0.105318    0.146388    0.945826         0.895072     0.763086   \n",
      "17     0.090598    0.125598    0.954454         0.904975     0.789383   \n",
      "18     0.104562    0.147583    0.951103         0.903404     0.774691   \n",
      "19     0.095380    0.126469    0.958693         0.911330     0.799877   \n",
      "20     0.082374    0.175980    0.940526         0.878232     0.760000   \n",
      "21     0.084462    0.118311    0.957002         0.912688     0.790741   \n",
      "22     0.079177    0.141188    0.952311         0.901076     0.785802   \n",
      "23     0.072018    0.122202    0.959111         0.914561     0.789630   \n",
      "24     0.070412    0.125976    0.959648         0.917346     0.791111   \n",
      "25     0.064773    0.138613    0.951954         0.895746     0.790123   \n",
      "26     0.074075    0.130386    0.955687         0.908159     0.776914   \n",
      "27     0.064841    0.134484    0.956652         0.909269     0.794197   \n",
      "28     0.074575    0.136588    0.952822         0.901926     0.789506   \n",
      "29     0.051306    0.118422    0.960334         0.917875     0.797901   \n",
      "30     0.055676    0.133500    0.957875         0.915164     0.799753   \n",
      "31     0.049184    0.142022    0.953906         0.905995     0.801852   \n",
      "32     0.046287    0.139566    0.958017         0.915114     0.802099   \n",
      "33     0.054363    0.138272    0.958167         0.916303     0.803457   \n",
      "34     0.042452    0.127801    0.962717         0.920849     0.808272   \n",
      "35     0.042087    0.131523    0.961329         0.917437     0.807778   \n",
      "36     0.038103    0.124702    0.964163         0.923801     0.810741   \n",
      "37     0.037724    0.128844    0.963046         0.921845     0.811111   \n",
      "38     0.043778    0.127039    0.963077         0.921248     0.811605   \n",
      "39     0.041916    0.126825    0.962762         0.920222     0.815062   \n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.335300    0.550128    0.958411         0.913239     0.787778   \n",
      "1      0.289344    0.499971    0.953955         0.905045     0.795556   \n",
      "2      0.286244    0.455537    0.951327         0.905535     0.800000   \n",
      "3      0.281397    0.402814    0.964946         0.928477     0.816296   \n",
      "4      0.291695    0.439483    0.956143         0.907261     0.806049   \n",
      "5      0.254448    0.395974    0.962274         0.921155     0.812099   \n",
      "6      0.329348    0.409972    0.951070         0.903354     0.805679   \n",
      "7      0.270968    0.417319    0.951737         0.898242     0.804815   \n",
      "8      0.278479    0.387914    0.953642         0.903498     0.814815   \n",
      "9      0.255646    0.407527    0.945769         0.888757     0.801358   \n",
      "10     0.242371    0.377592    0.954813         0.908132     0.813086   \n",
      "11     0.249258    0.375222    0.954088         0.906254     0.811728   \n",
      "12     0.251249    0.357558    0.956941         0.907152     0.817407   \n",
      "13     0.250691    0.372838    0.945921         0.891673     0.813210   \n",
      "14     0.254036    0.362642    0.954431         0.903843     0.811235   \n",
      "15     0.232665    0.362720    0.961092         0.913992     0.817778   \n",
      "16     0.229179    0.358038    0.958112         0.910234     0.816049   \n",
      "17     0.236970    0.366803    0.950208         0.899070     0.810247   \n",
      "18     0.210717    0.350168    0.960351         0.910529     0.822346   \n",
      "19     0.215242    0.342809    0.959254         0.910871     0.832222   \n",
      "20     0.213280    0.370212    0.954307         0.902087     0.822346   \n",
      "21     0.228533    0.334937    0.957470         0.911412     0.826543   \n",
      "22     0.218595    0.339316    0.956347         0.909346     0.826543   \n",
      "23     0.213281    0.348211    0.954895         0.907661     0.819506   \n",
      "24     0.183338    0.339916    0.957415         0.913507     0.825803   \n",
      "25     0.171757    0.336021    0.957130         0.911184     0.829136   \n",
      "26     0.178250    0.344363    0.956432         0.909920     0.828025   \n",
      "27     0.200357    0.319514    0.961289         0.919745     0.835802   \n",
      "28     0.173891    0.320959    0.956913         0.911722     0.832099   \n",
      "29     0.170579    0.315362    0.961564         0.919692     0.835062   \n",
      "30     0.164224    0.319230    0.962449         0.919361     0.834445   \n",
      "31     0.164518    0.320755    0.962392         0.921017     0.839383   \n",
      "32     0.152814    0.315190    0.963345         0.921364     0.838148   \n",
      "33     0.155725    0.314185    0.956203         0.908346     0.834691   \n",
      "34     0.152268    0.305910    0.963241         0.921629     0.840000   \n",
      "35     0.144802    0.314666    0.963439         0.920219     0.837654   \n",
      "36     0.135418    0.307891    0.962837         0.919528     0.842469   \n",
      "37     0.128185    0.297103    0.962846         0.923738     0.842222   \n",
      "38     0.151152    0.301385    0.962013         0.922799     0.841975   \n",
      "39     0.139729    0.300070    0.962545         0.920374     0.840123   \n",
      "### Starting to train fold 2 ###\n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.319356    0.294260    0.877194         0.767619     0.383920   \n",
      "1      0.252641    0.198510    0.930251         0.848453     0.581910   \n",
      "2      0.242463    0.176266    0.938362         0.861012     0.650377   \n",
      "3      0.223121    0.178117    0.938128         0.863996     0.653141   \n",
      "4      0.235734    0.176193    0.938539         0.867120     0.655276   \n",
      "5      0.223726    0.168456    0.942245         0.875156     0.680528   \n",
      "6      0.213550    0.155629    0.945379         0.884122     0.677387   \n",
      "7      0.196907    0.149046    0.949291         0.892007     0.692085   \n",
      "8      0.175617    0.143605    0.949239         0.893197     0.697362   \n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.167724    0.140576    0.948527         0.890344     0.714950   \n",
      "1      0.175943    0.133483    0.952314         0.898535     0.717588   \n",
      "2      0.164967    0.136858    0.952591         0.899713     0.708668   \n",
      "3      0.145660    0.129514    0.953123         0.898682     0.720854   \n",
      "4      0.167230    0.133158    0.955226         0.902895     0.725628   \n",
      "5      0.140339    0.136817    0.953666         0.901303     0.737437   \n",
      "6      0.141374    0.139474    0.951707         0.892450     0.745477   \n",
      "7      0.135378    0.160323    0.942023         0.875226     0.715955   \n",
      "8      0.133546    0.131357    0.955535         0.906592     0.738191   \n",
      "9      0.115481    0.192149    0.931664         0.858688     0.674372   \n",
      "10     0.118702    0.117383    0.958432         0.911486     0.748744   \n",
      "11     0.131747    0.129980    0.954852         0.900707     0.734045   \n",
      "12     0.112078    0.148304    0.945305         0.891102     0.737060   \n",
      "13     0.108566    0.133852    0.950824         0.890914     0.751759   \n",
      "14     0.104351    0.127101    0.959859         0.915634     0.758040   \n",
      "15     0.106251    0.132521    0.957202         0.907893     0.761809   \n",
      "16     0.095785    0.147568    0.950097         0.892637     0.734045   \n",
      "17     0.088855    0.147392    0.947863         0.890467     0.758166   \n",
      "18     0.081887    0.128901    0.958936         0.912325     0.773492   \n",
      "19     0.088518    0.139385    0.956190         0.907536     0.758668   \n",
      "20     0.086682    0.174583    0.934169         0.859328     0.717714   \n",
      "21     0.090687    0.157829    0.953002         0.901887     0.754271   \n",
      "22     0.097707    0.135825    0.952298         0.901841     0.750502   \n",
      "23     0.085580    0.136999    0.954718         0.906041     0.761558   \n",
      "24     0.075431    0.116001    0.961133         0.920477     0.767965   \n",
      "25     0.069311    0.129696    0.958730         0.910550     0.765201   \n",
      "26     0.064880    0.138259    0.955083         0.906778     0.769598   \n",
      "27     0.067914    0.135627    0.960346         0.919717     0.762688   \n",
      "28     0.055385    0.146384    0.955469         0.908006     0.765578   \n",
      "29     0.058138    0.134199    0.954378         0.908122     0.766834   \n",
      "30     0.060052    0.147641    0.956586         0.911024     0.774121   \n",
      "31     0.077778    0.123976    0.959714         0.913431     0.776382   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32     0.069241    0.130908    0.959344         0.914335     0.788317   \n",
      "33     0.055058    0.113291    0.963365         0.924636     0.788442   \n",
      "34     0.050961    0.118900    0.961221         0.922391     0.782412   \n",
      "35     0.050907    0.114355    0.961734         0.920464     0.786683   \n",
      "36     0.054301    0.127416    0.955649         0.909541     0.775251   \n",
      "37     0.043234    0.120443    0.959238         0.915377     0.779899   \n",
      "38     0.043766    0.118285    0.961378         0.919641     0.784422   \n",
      "39     0.043657    0.116251    0.961393         0.919486     0.785176   \n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.349438    0.548896    0.958247         0.914122     0.774874   \n",
      "1      0.317679    0.529517    0.955818         0.905428     0.775000   \n",
      "2      0.276960    0.479133    0.948324         0.894627     0.782161   \n",
      "3      0.355264    0.511307    0.953570         0.902747     0.767085   \n",
      "4      0.305606    0.452097    0.955725         0.906378     0.778518   \n",
      "5      0.294124    0.415229    0.954332         0.901856     0.789824   \n",
      "6      0.265545    0.460051    0.945815         0.886349     0.776759   \n",
      "7      0.253761    0.402343    0.959709         0.916362     0.805276   \n",
      "8      0.398822    0.468124    0.939562         0.873177     0.757161   \n",
      "9      0.300390    0.396050    0.957385         0.907464     0.791332   \n",
      "10     0.294500    0.364880    0.960933         0.919865     0.801633   \n",
      "11     0.294768    0.398921    0.954667         0.906711     0.794221   \n",
      "12     0.261794    0.448490    0.931091         0.854488     0.767714   \n",
      "13     0.248196    0.367239    0.956887         0.909990     0.788317   \n",
      "14     0.224641    0.382450    0.959918         0.913951     0.802136   \n",
      "15     0.240210    0.397691    0.946983         0.882214     0.784548   \n",
      "16     0.260967    0.384751    0.955248         0.903360     0.804146   \n",
      "17     0.265086    0.354248    0.959930         0.917356     0.810176   \n",
      "18     0.252658    0.359999    0.959595         0.910597     0.807412   \n",
      "19     0.227860    0.350333    0.953752         0.903474     0.801633   \n",
      "20     0.227136    0.373096    0.955471         0.908364     0.798116   \n",
      "21     0.237879    0.354903    0.960211         0.918197     0.805653   \n",
      "22     0.232071    0.398801    0.946524         0.885534     0.788568   \n",
      "23     0.229399    0.334823    0.955273         0.908941     0.806533   \n",
      "24     0.247632    0.334190    0.961938         0.918273     0.805151   \n",
      "25     0.224925    0.339005    0.960623         0.920749     0.812940   \n",
      "26     0.187724    0.350335    0.957546         0.910912     0.804146   \n",
      "27     0.187301    0.345915    0.961844         0.919930     0.809045   \n",
      "28     0.180735    0.331245    0.958838         0.912065     0.809296   \n",
      "29     0.179359    0.312245    0.966211         0.929992     0.819347   \n",
      "30     0.171295    0.318035    0.965863         0.927171     0.819095   \n",
      "31     0.163664    0.320909    0.960283         0.916807     0.816583   \n",
      "32     0.177577    0.313078    0.963450         0.923287     0.820100   \n",
      "33     0.153251    0.321791    0.960222         0.918252     0.814699   \n",
      "34     0.205172    0.310640    0.964318         0.926972     0.819347   \n",
      "35     0.155454    0.310355    0.961216         0.919973     0.820980   \n",
      "36     0.143098    0.314571    0.960594         0.917855     0.819849   \n",
      "37     0.134736    0.308760    0.962049         0.922914     0.822487   \n",
      "38     0.141331    0.306682    0.964737         0.927835     0.825628   \n",
      "39     0.132668    0.306085    0.961222         0.921574     0.822487   \n",
      "### Starting to train fold 3 ###\n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.298629    0.248637    0.903838         0.807072     0.448673   \n",
      "1      0.270665    0.198114    0.934368         0.854402     0.567636   \n",
      "2      0.244662    0.177026    0.939596         0.858811     0.661947   \n",
      "3      0.237887    0.165021    0.943322         0.870610     0.652718   \n",
      "4      0.218852    0.175259    0.941097         0.864394     0.662073   \n",
      "5      0.248653    0.171170    0.946929         0.884432     0.654109   \n",
      "6      0.218488    0.156362    0.947906         0.883589     0.688243   \n",
      "7      0.199665    0.145182    0.949316         0.892520     0.678003   \n",
      "8      0.197488    0.130498    0.955105         0.902632     0.714159   \n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.177505    0.136705    0.952349         0.899668     0.706574   \n",
      "1      0.176382    0.136211    0.953026         0.899988     0.709355   \n",
      "2      0.168736    0.126144    0.956239         0.905938     0.717193   \n",
      "3      0.155961    0.123381    0.956956         0.909670     0.734640   \n",
      "4      0.170107    0.119429    0.957208         0.910555     0.738179   \n",
      "5      0.138542    0.131378    0.954651         0.898590     0.730341   \n",
      "6      0.144315    0.110978    0.961505         0.919389     0.758154   \n",
      "7      0.143855    0.121085    0.956198         0.910932     0.754614   \n",
      "8      0.150921    0.112186    0.959505         0.918106     0.752718   \n",
      "9      0.126329    0.111821    0.963190         0.923952     0.774463   \n",
      "10     0.136346    0.110571    0.960741         0.916694     0.745765   \n",
      "11     0.131157    0.107758    0.964712         0.927207     0.774968   \n",
      "12     0.123277    0.114699    0.958218         0.915074     0.762958   \n",
      "13     0.109637    0.117428    0.960842         0.918876     0.775348   \n",
      "14     0.099328    0.122979    0.957083         0.915239     0.758786   \n",
      "15     0.118385    0.122096    0.956714         0.909549     0.764602   \n",
      "16     0.123728    0.132671    0.954518         0.904463     0.765487   \n",
      "17     0.088546    0.118645    0.963435         0.927716     0.769027   \n",
      "18     0.091502    0.131606    0.956787         0.912850     0.770796   \n",
      "19     0.090569    0.135900    0.953813         0.905660     0.766372   \n",
      "20     0.093644    0.117279    0.958062         0.911485     0.771176   \n",
      "21     0.085551    0.101218    0.963914         0.928430     0.795322   \n",
      "22     0.079571    0.139501    0.950240         0.900208     0.755373   \n",
      "23     0.082835    0.123376    0.958184         0.908579     0.777244   \n",
      "24     0.073023    0.117731    0.961312         0.919151     0.788369   \n",
      "25     0.076975    0.126284    0.957424         0.909354     0.772946   \n",
      "26     0.063634    0.117305    0.964160         0.923660     0.795449   \n",
      "27     0.064540    0.123465    0.955809         0.906820     0.784703   \n",
      "28     0.065470    0.101887    0.964894         0.928358     0.794817   \n",
      "29     0.052661    0.107509    0.965355         0.928523     0.798736   \n",
      "30     0.060214    0.102207    0.965603         0.929846     0.796334   \n",
      "31     0.048723    0.101085    0.966603         0.932451     0.801011   \n",
      "32     0.046774    0.112361    0.965369         0.931551     0.791530   \n",
      "33     0.043508    0.111261    0.965731         0.931635     0.796587   \n",
      "34     0.038993    0.104918    0.967423         0.934614     0.799241   \n",
      "35     0.039565    0.106866    0.966964         0.933904     0.799494   \n",
      "36     0.036130    0.100297    0.968609         0.936876     0.805310   \n",
      "37     0.037349    0.102166    0.967876         0.935889     0.798104   \n",
      "38     0.040207    0.102976    0.967719         0.935301     0.805057   \n",
      "39     0.035488    0.102613    0.968040         0.936061     0.803034   \n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.335594    0.496574    0.965109         0.926894     0.798609   \n",
      "1      0.286421    0.453280    0.964619         0.928432     0.812769   \n",
      "2      0.293567    0.448381    0.965577         0.931166     0.806195   \n",
      "3      0.268472    0.424154    0.966292         0.928415     0.809861   \n",
      "4      0.268041    0.406902    0.966839         0.932736     0.805057   \n",
      "5      0.329143    0.438727    0.954124         0.906631     0.788116   \n",
      "6      0.274393    0.399579    0.964213         0.926320     0.809608   \n",
      "7      0.325178    0.404256    0.959588         0.917361     0.800253   \n",
      "8      0.263396    0.356280    0.963199         0.920456     0.817699   \n",
      "9      0.618730    0.534814    0.934490         0.850590     0.707585   \n",
      "10     0.516365    0.508238    0.935091         0.855519     0.725664   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11     0.466803    0.434028    0.944607         0.879306     0.754362   \n",
      "12     0.408035    0.397253    0.957798         0.910830     0.784576   \n",
      "13     0.338551    0.378640    0.955105         0.909425     0.790771   \n",
      "14     0.341515    0.403127    0.953351         0.899155     0.779140   \n",
      "15     0.306665    0.351109    0.959846         0.917627     0.803540   \n",
      "16     0.297312    0.366306    0.953602         0.906867     0.797977   \n",
      "17     0.309059    0.363109    0.958605         0.916138     0.805310   \n",
      "18     0.280014    0.370274    0.953803         0.906348     0.796207   \n",
      "19     0.259707    0.352134    0.956494         0.906749     0.803161   \n",
      "20     0.263348    0.362767    0.953175         0.895242     0.800253   \n",
      "21     0.259242    0.347158    0.958804         0.919124     0.802781   \n",
      "22     0.246756    0.329762    0.961557         0.918823     0.810240   \n",
      "23     0.257627    0.344757    0.959870         0.916120     0.806827   \n",
      "24     0.240486    0.341810    0.960732         0.918952     0.811884   \n",
      "25     0.223360    0.323682    0.960692         0.920135     0.820986   \n",
      "26     0.218756    0.327504    0.956229         0.914106     0.809102   \n",
      "27     0.207405    0.338576    0.954835         0.911095     0.814539   \n",
      "28     0.204124    0.313535    0.962206         0.924298     0.824273   \n",
      "29     0.200667    0.317960    0.963135         0.925738     0.825032   \n",
      "30     0.201970    0.331404    0.956687         0.913532     0.806827   \n",
      "31     0.182626    0.309513    0.962612         0.927753     0.824273   \n",
      "32     0.187904    0.295885    0.966588         0.935240     0.832364   \n",
      "33     0.176754    0.319442    0.953728         0.904436     0.818331   \n",
      "34     0.161693    0.301072    0.960331         0.922029     0.822377   \n",
      "35     0.172874    0.297215    0.962216         0.925361     0.828192   \n",
      "36     0.150412    0.298302    0.962804         0.928737     0.825537   \n",
      "37     0.148901    0.294779    0.963157         0.929827     0.831353   \n",
      "38     0.147347    0.294991    0.963648         0.930669     0.831100   \n",
      "39     0.160434    0.296107    0.960967         0.926274     0.830721   \n",
      "### Starting to train fold 4 ###\n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.283968    0.221937    0.918066         nan          0.552357   \n",
      "1      0.259261    0.199055    0.934140         nan          0.640764   \n",
      "2      0.235660    0.180929    0.935574         nan          0.654777   \n",
      "3      0.223617    0.181487    0.936441         nan          0.679618   \n",
      "4      0.216533    0.200295    0.926747         nan          0.643567   \n",
      "5      0.208199    0.167198    0.939798         nan          0.711210   \n",
      "6      0.199918    0.162116    0.944045         nan          0.709299   \n",
      "7      0.180750    0.155571    0.948710         nan          0.727898   \n",
      "8      0.178305    0.152720    0.948861         nan          0.731338   \n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.169477    0.151530    0.947663         nan          0.726242   \n",
      "1      0.176240    0.143561    0.948759         nan          0.730064   \n",
      "2      0.150181    0.137529    0.953485         nan          0.757707   \n",
      "3      0.154467    0.142834    0.952262         nan          0.754777   \n",
      "4      0.165138    0.132759    0.953959         nan          0.764713   \n",
      "5      0.141661    0.131993    0.953987         nan          0.765860   \n",
      "6      0.144955    0.131012    0.956025         nan          0.772229   \n",
      "7      0.139885    0.120430    0.956797         nan          0.786624   \n",
      "9      0.136203    0.123860    0.958492         nan          0.771847   \n",
      "10     0.122619    0.129093    0.952615         nan          0.776178   \n",
      "11     0.117475    0.115655    0.960800         nan          0.791720   \n",
      "12     0.104583    0.127070    0.957037         nan          0.797197   \n",
      "13     0.111888    0.131118    0.952227         nan          0.783057   \n",
      "14     0.099544    0.114614    0.963972         nan          0.807006   \n",
      "15     0.102967    0.143390    0.944190         nan          0.777197   \n",
      "16     0.117352    0.117450    0.958381         nan          0.780764   \n",
      "17     0.105042    0.130898    0.952508         nan          0.794013   \n",
      "18     0.108326    0.125753    0.955850         nan          0.792229   \n",
      "19     0.120029    0.133793    0.945029         nan          0.773631   \n",
      "20     0.102325    0.121482    0.960199         nan          0.802548   \n",
      "21     0.078218    0.136420    0.959133         nan          0.807389   \n",
      "22     0.084502    0.117728    0.962038         nan          0.801529   \n",
      "23     0.086050    0.117580    0.964640         nan          0.812484   \n",
      "24     0.071918    0.123642    0.962498         nan          0.810064   \n",
      "25     0.078413    0.113355    0.961394         nan          0.807898   \n",
      "26     0.078343    0.119875    0.958444         nan          0.799873   \n",
      "27     0.066977    0.118093    0.963575         nan          0.807389   \n",
      "28     0.062403    0.120162    0.965181         nan          0.816051   \n",
      "29     0.051658    0.114631    0.964992         nan          0.820255   \n",
      "30     0.054307    0.131128    0.956372         nan          0.803949   \n",
      "31     0.044290    0.119678    0.962634         nan          0.815287   \n",
      "32     0.048475    0.124786    0.959633         nan          0.810446   \n",
      "33     0.045024    0.124667    0.961989         nan          0.811083   \n",
      "34     0.043680    0.115420    0.963941         nan          0.818471   \n",
      "35     0.040458    0.119557    0.964268         nan          0.817707   \n",
      "36     0.040903    0.127117    0.963528         nan          0.826369   \n",
      "37     0.038699    0.117442    0.965828         nan          0.815669   \n",
      "38     0.040245    0.118628    0.964320         nan          0.820764   \n",
      "39     0.037593    0.119882    0.964110         nan          0.825733   \n",
      "epoch  train loss  valid loss  accuracy_no_pad  dice_no_pad  iou_pytorch\n",
      "0      0.335617    0.449040    0.960665         nan          0.805860   \n",
      "1      0.305967    0.394807    0.964193         nan          0.824459   \n",
      "2      0.364506    0.527819    0.952743         nan          0.786879   \n",
      "3      0.403406    0.479924    0.933799         nan          0.771465   \n",
      "4      0.662381    0.551459    0.933100         nan          0.711083   \n",
      "5      0.403173    0.409682    0.946355         nan          0.778344   \n",
      "6      0.360011    0.338382    0.954900         nan          0.809299   \n",
      "7      0.303702    0.327062    0.955523         nan          0.808408   \n",
      "8      0.290856    0.323635    0.958278         nan          0.819490   \n",
      "9      0.285570    0.329423    0.956277         nan          0.819363   \n",
      "10     0.277043    0.330522    0.953954         nan          0.811338   \n",
      "11     0.287197    0.323503    0.955827         nan          0.813121   \n",
      "12     0.280661    0.340526    0.951643         nan          0.822166   \n",
      "13     0.275198    0.326370    0.957246         nan          0.816943   \n",
      "14     0.266841    0.299372    0.961357         nan          0.832357   \n",
      "15     0.250195    0.391631    0.915316         nan          0.785223   \n",
      "16     0.235897    0.300085    0.958419         nan          0.831465   \n",
      "17     0.245575    0.303899    0.959820         nan          0.832102   \n",
      "18     0.233126    0.333124    0.954704         nan          0.812739   \n",
      "19     0.225718    0.288458    0.964829         nan          0.836306   \n",
      "20     0.238740    0.279675    0.960355         nan          0.838726   \n",
      "21     0.218253    0.278293    0.962687         nan          0.844331   \n",
      "22     0.218547    0.318979    0.954777         nan          0.827261   \n",
      "23     0.203466    0.286676    0.954474         nan          0.842166   \n",
      "24     0.205047    0.274595    0.961642         nan          0.842675   \n",
      "25     0.191277    0.273321    0.963046         nan          0.839873   \n",
      "26     0.204840    0.270962    0.963788         nan          0.842420   \n",
      "27     0.181106    0.274811    0.960161         nan          0.842803   \n",
      "28     0.193035    0.311084    0.946965         nan          0.824076   \n",
      "29     0.181098    0.273385    0.961122         nan          0.843440   \n",
      "30     0.177289    0.280515    0.958075         nan          0.841274   \n",
      "31     0.153397    0.255815    0.965548         nan          0.850828   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32     0.170452    0.267429    0.961744         nan          0.845860   \n",
      "33     0.151671    0.255015    0.964170         nan          0.853376   \n",
      "34     0.152295    0.252835    0.964984         nan          0.854904   \n",
      "35     0.155099    0.248925    0.964353         nan          0.852484   \n",
      "36     0.143878    0.257782    0.964240         nan          0.854268   \n",
      "37     0.153231    0.251785    0.962975         nan          0.854013   \n",
      "38     0.145596    0.251433    0.961087         nan          0.852611   \n",
      "39     0.154005    0.246733    0.965504         nan          0.856051   \n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "for fold in folds_to_train:\n",
    "    print(f'### Starting to train fold {fold} ###')\n",
    "    db = get_data_bunch(sz=202, bs=16, part=fold, trn_tfms=trn_tfms)\n",
    "    learn = get_learner(db)\n",
    "    requires_grad(learn.model, True)\n",
    "    requires_grad(learn.model.rn, False)\n",
    "    learn.fit_one_cycle(9, 1e-1)\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(40, 1e-2)\n",
    "    learn.loss_fn = lovasz_loss\n",
    "    learn.fit_one_cycle(40, 5e-3)\n",
    "    learn.save(f'{name}_fold{fold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 val acc: 0.9501998222044965, iou: 0.845721271393643\n",
      "Fold 0 best iou val acc: 0.9493975793158972, iou: 0.8458435207823961\n",
      "Fold 1 val acc: 0.9632002611702314, iou: 0.847037037037037\n",
      "Fold 1 best iou val acc: 0.9632002309141805, iou: 0.847037037037037\n",
      "Fold 2 val acc: 0.9654787083638957, iou: 0.8310301507537688\n",
      "Fold 2 best iou val acc: 0.9654787083638957, iou: 0.8310301507537688\n",
      "Fold 3 val acc: 0.9635732026470224, iou: 0.8353982300884957\n",
      "Fold 3 best iou val acc: 0.9646339610491572, iou: 0.8383059418457648\n",
      "Fold 4 val acc: 0.9652535001876299, iou: 0.8547770700636943\n",
      "Fold 4 best iou val acc: 0.9679710743982263, iou: 0.8596178343949044\n",
      "CPU times: user 37min 49s, sys: 12min 46s, total: 50min 35s\n",
      "Wall time: 47min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "upside_down = False\n",
    "\n",
    "for fold in folds_to_train:\n",
    "    db = get_data_bunch(sz=202, bs=16, part=fold, trn_tfms=trn_tfms)\n",
    "    learn = get_learner(db)\n",
    "    \n",
    "    learn.load(f'{name}_fold{fold}')\n",
    "    val_preds, val_targs = predict_with_targs_and_TTA(learn.model, db.valid_dl, upside_down)\n",
    "    test_preds = predict_with_TTA(learn.model, db.test_dl, upside_down)\n",
    "    val_preds, test_preds = normalize_t(val_preds, val_targs, test_preds)\n",
    "    print(f'Fold {fold} val acc: {accuracy_np(val_preds, val_targs)}, iou: {iou_metric(val_targs, val_preds > 0.5)}')\n",
    "    \n",
    "    \n",
    "    np.save(f'/home/radek/db/salt/val_preds_{name}_fold{fold}', val_preds)\n",
    "    np.save(f'/home/radek/db/salt/val_targs_{name}_fold{fold}', val_targs)\n",
    "    np.save(f'/home/radek/db/salt/test_preds_{name}_fold{fold}', test_preds)\n",
    "    del val_preds, val_targs, test_preds\n",
    "    \n",
    "    \n",
    "    learn.load(f'{name}_best_iou_fold{fold}')\n",
    "    val_preds, val_targs = predict_with_targs_and_TTA(learn.model, db.valid_dl, upside_down)\n",
    "    test_preds = predict_with_TTA(learn.model, db.test_dl, upside_down)\n",
    "    \n",
    "    val_preds, test_preds = normalize_t(val_preds, val_targs, test_preds)\n",
    "    print(f'Fold {fold} best iou val acc: {accuracy_np(val_preds, val_targs)}, iou: {iou_metric(val_targs, val_preds > 0.5)}')\n",
    "    \n",
    "    np.save(f'/home/radek/db/salt/val_preds_{name}_best_iou_fold{fold}', val_preds)\n",
    "    np.save(f'/home/radek/db/salt/test_{name}_best_iou_fold{fold}', test_preds)\n",
    "    del val_preds, val_targs, test_preds\n",
    "    \n",
    "    learn.model.close()\n",
    "    del learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 20.6 s, total: 31.1 s\n",
      "Wall time: 57.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ys = []\n",
    "preds = []\n",
    "test_preds = np.zeros((18000, 202, 202))\n",
    "for fold in folds_to_train:\n",
    "    y = np.load(f'/home/radek/db/salt/val_targs_{name}_fold{fold}.npy')\n",
    "    val_preds = np.load(f'/home/radek/db/salt/val_preds_{name}_fold{fold}.npy')\n",
    "    preds.append(val_preds)\n",
    "    ys.append(y)\n",
    "    test_pred = np.load(f'/home/radek/db/salt/test_preds_{name}_fold{fold}.npy')\n",
    "    test_preds += test_pred / len(folds_to_train)\n",
    "\n",
    "np.save(f'/home/radek/db/salt/val_preds_{name}.npy', np.concatenate(preds))\n",
    "np.save(f'/home/radek/db/salt/val_targs_{name}.npy', np.concatenate(ys))\n",
    "np.save(f'/home/radek/db/salt/test_preds_{name}.npy', test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 0: 0.9493975793158972, 0.8458435207823961, 0.49999999999999994\n",
      "Part 1: 0.9632002611702314, 0.847037037037037, 0.49999999999999994\n",
      "Part 2: 0.9654787083638957, 0.8310301507537688, 0.49999999999999994\n",
      "Part 3: 0.9646339610491572, 0.8383059418457648, 0.49999999999999994\n",
      "Part 4: 0.9679710743982263, 0.8596178343949044, 0.49999999999999994\n",
      "CPU times: user 11.5 s, sys: 580 ms, total: 12.1 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for fold in folds_to_train:\n",
    "    val_preds = np.load(f'/home/radek/db/salt/val_preds_{name}_fold{fold}.npy')\n",
    "    val_targs = np.load(f'/home/radek/db/salt/val_targs_{name}_fold{fold}.npy')\n",
    "    print(f'Fold {fold}: {accuracy_np(val_preds, val_targs)}, {iou_metric(val_targs, val_preds > 0.5)}, {best_preds_t(val_preds, val_targs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = np.load(f'/home/radek/db/salt/val_preds_{name}.npy')\n",
    "val_targs = np.load(f'/home/radek/db/salt/val_targs_{name}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84435"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_metric(val_targs, val_preds > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = np.load(f'/home/radek/db/salt/val_preds_{name}_fold4.npy')\n",
    "val_targs = np.load(f'/home/radek/db/salt/val_targs_{name}_fold4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8596178343949044"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_metric(val_targs, val_preds > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798d00f38ef94228bb416976a8f85329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run diagnostics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.load(f'/home/radek/db/salt/test_preds_{name}_fold4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_to_sub(test_preds, db.test_dl.dl.dataset.x, 0.5, 150, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to TGS Salt Identification Challenge"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c tgs-salt-identification-challenge -f ../subs/{name}.csv.gz  -m {name}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
