{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import albumentations\n",
    "import pretrainedmodels\n",
    "from IPython.core.debugger import set_trace\n",
    "from tqdm import tqdm_notebook\n",
    "import skimage\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from nb_006 import *\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = Path('../data')\n",
    "TRAIN_DN = 'train'\n",
    "TEST_DN = 'test'\n",
    "IMAGES = 'images'\n",
    "MASKS = 'masks'\n",
    "\n",
    "DEPTHS_FN = 'depths.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_means, imagenet_std = map(np.array, ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "\n",
    "normalize = lambda x: (x - imagenet_means) / imagenet_std\n",
    "denormalize = lambda x: x * imagenet_std + imagenet_means\n",
    "\n",
    "def open_image(fn):\n",
    "    x = PIL.Image.open(fn).convert('RGB')\n",
    "    return normalize(np.asarray(x) / 255)\n",
    "\n",
    "def open_mask(fn):\n",
    "    x = PIL.Image.open(fn)\n",
    "    return np.asarray(x) / 65535\n",
    "\n",
    "def show_image(im, figsize=None, ax=None, alpha=None):\n",
    "    if im.shape[0] == 3: im = im.transpose(1,2,0)\n",
    "    if im.min() < 0 and im.ndim == 3: im=denormalize(im); im = np.clip(im, 0, 1) # this is quite horrible and can lead to bugs\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax\n",
    "\n",
    "class FilesDataset(DatasetBase):\n",
    "    def __init__(self, folder, sz, take_idxs=None, tfms=None):\n",
    "        sub_folders = list(p.stem for p in (folder/str(sz)).iterdir())\n",
    "        self.x = list((folder/str(sz)/'images').iterdir())\n",
    "        if take_idxs is not None:\n",
    "            self.x = [self.x[idx] for idx in take_idxs]\n",
    "        if 'masks' in sub_folders:\n",
    "            self.y = list((folder/str(sz)/'masks').iterdir())\n",
    "            if take_idxs is not None:\n",
    "                self.y = [self.y[idx] for idx in take_idxs]\n",
    "            assert np.all([p1.stem == p2.stem for p1, p2 in zip(self.x, self.y)]) and len(self.x) == len(self.y), \\\n",
    "                'filenames between self.x and self.y do not match'\n",
    "        self.tfms = tfms\n",
    "            \n",
    "    def __getitem__(self,i):\n",
    "        im = open_image(self.x[i])\n",
    "        if hasattr(self, 'y'):\n",
    "            mask = open_mask(self.y[i])\n",
    "        else:\n",
    "            mask = np.zeros_like(im)[0]\n",
    "        if self.tfms is not None:\n",
    "            transformed = self.tfms(image=im, mask=mask)\n",
    "            im, mask = transformed['image'], transformed['mask']        \n",
    "        im = im.transpose(2, 0, 1)\n",
    "        im, mask = map(lambda x: x.astype(np.float32), [im, mask])\n",
    "        return im, mask\n",
    "    \n",
    "    def show_im_with_mask(self, idx, axes=None):\n",
    "        im, mask = self[idx]\n",
    "        if axes is None: _, axes = plt.subplots(1, 2)\n",
    "        show_image(im, ax=axes[0])\n",
    "        show_image(mask, ax=axes[1])\n",
    "        \n",
    "    def check_tfms(self, idx, n=5, figsize=(10,4)):\n",
    "        _, axes = plt.subplots(2, n, figsize=figsize)\n",
    "        for i in range(n):\n",
    "            self.show_im_with_mask(idx, axes=(axes[0][i], axes[1][i]))\n",
    "\n",
    "n = len(list((PATH/TRAIN_DN/'128/images').iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "# idxs = np.arange(n)\n",
    "# np.random.shuffle(idxs)\n",
    "\n",
    "# val_parts = [idxs[i*800:(i+1)*800] for i in range(5)]\n",
    "# trn_parts = [[idx for idx in idxs if idx not in val_parts[i]] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_sizes = {}\n",
    "# for p in (PATH/TRAIN_DN/'128/masks').iterdir():\n",
    "#     img = PIL.Image.open(p)\n",
    "#     mask_sizes[p.stem] = np.sum(np.asarray(img) != 0)\n",
    "\n",
    "# pd.to_pickle(mask_sizes, PATH/'mask_sizes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_sizes = pd.read_pickle(PATH/'mask_sizes.pkl')\n",
    "\n",
    "# depths = pd.read_csv(PATH/DEPTHS_FN)\n",
    "# depths.set_index('id',drop=True, inplace=True)\n",
    "# depths = depths.to_dict()['z']\n",
    "\n",
    "# fns = [p.stem for p in (PATH/TRAIN_DN/'128/images').iterdir()]\n",
    "# trn_df = pd.DataFrame(data={'fn': fns})\n",
    "# trn_df['coverage'] = trn_df['fn'].apply(lambda x: mask_sizes[x])\n",
    "# trn_df.coverage /= trn_df.coverage.max()\n",
    "\n",
    "# def cov_class(v):\n",
    "#     for i in range(9, -1, -1):\n",
    "#         if v * 10 >= i: return i\n",
    "\n",
    "# trn_df['cov_class'] = trn_df.coverage.apply(lambda x: cov_class(x))\n",
    "\n",
    "# trn_df.to_csv(PATH/'trn_df_with_cov.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = pd.read_csv(PATH/'trn_df_with_cov.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>coverage</th>\n",
       "      <th>cov_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7a124fff5</td>\n",
       "      <td>0.980712</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8620f40403</td>\n",
       "      <td>0.210218</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ae11c7b131</td>\n",
       "      <td>0.529207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57293a65d5</td>\n",
       "      <td>0.731612</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d69c382be5</td>\n",
       "      <td>0.083257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fn  coverage  cov_class\n",
       "0  a7a124fff5  0.980712          9\n",
       "1  8620f40403  0.210218          2\n",
       "2  ae11c7b131  0.529207          5\n",
       "3  57293a65d5  0.731612          7\n",
       "4  d69c382be5  0.083257          0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = list(skf.split(np.zeros(n), trn_df.cov_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_parts = [parts[i][1] for i in range(5)]\n",
    "trn_parts = [parts[i][0] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "# idxs = np.arange(n)\n",
    "# np.random.shuffle(idxs)\n",
    "\n",
    "# val_parts = [idxs[i*800:(i+1)*800] for i in range(5)]\n",
    "# trn_parts = [[idx for idx in idxs if idx not in val_parts[i]] for i in range(5)]\n",
    "\n",
    "@dataclass()\n",
    "class DataBunch():\n",
    "    train_dl:DataLoader\n",
    "    valid_dl:DataLoader\n",
    "    test_dl:DataLoader\n",
    "    device:torch.device=None\n",
    "\n",
    "# def get_data_bunch(sz=128, bs=64, part=0, trn_tfms=None):\n",
    "#     trn_ds = FilesDataset(PATH/TRAIN_DN, sz, take_idxs=trn_parts[part], tfms=trn_tfms)\n",
    "#     val_ds = FilesDataset(PATH/TRAIN_DN, sz, take_idxs=val_parts[part])\n",
    "#     tst_ds = FilesDataset(PATH/TEST_DN, sz)\n",
    "    \n",
    "#     trn_dl = DataLoader(trn_ds, bs, True, num_workers=11, pin_memory=True)\n",
    "#     val_dl = DataLoader(val_ds, 2*bs, False, num_workers=11, pin_memory=True)\n",
    "#     tst_dl = DataLoader(tst_ds, 2*bs, False, num_workers=11, pin_memory=True)\n",
    "    \n",
    "#     trn_dl, val_dl, tst_dl = map(lambda ts: DeviceDataLoader(*ts), zip([trn_dl, val_dl, tst_dl], [default_device] * 3) )\n",
    "#     return DataBunch(trn_dl, val_dl, tst_dl, default_device)\n",
    "\n",
    "def accuracy_thresh(out, yb, thresh=0.5):\n",
    "    preds = torch.sigmoid(out) > thresh\n",
    "    return (preds==yb.byte()).float().mean()\n",
    "\n",
    "def dice(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    return 2. * (pred*targs).sum() / (pred+targs).sum()\n",
    "\n",
    "def predict(model, dl, flip=True):\n",
    "    model.eval()\n",
    "    return np.concatenate([torch.sigmoid(model(xb)).detach().cpu().numpy() for xb, yb in dl])\n",
    "\n",
    "# def predict_with_targs(model, dl, flip=True):\n",
    "#     model.eval()\n",
    "#     preds_targs = [(model(xb).detach(), yb.detach().cpu().numpy()) for xb, yb in dl]\n",
    "#     preds, targs = list(zip(*preds_targs))\n",
    "#     if not flip:\n",
    "#         preds = [torch.sigmoid(pred).cpu().numpy() for pred in preds]\n",
    "#         return np.concatenate(preds), np.concatenate(targs)\n",
    "#     flipped_preds = [model(torch.flip(xb, [3])).detach() for xb, yb in dl]\n",
    "#     unflipped_preds = torch.flip(torch.cat(flipped_preds), [2])\n",
    "#     preds = (torch.cat(preds) + unflipped_preds) / 2\n",
    "#     return preds.sigmoid().cpu().numpy(), np.concatenate(targs)\n",
    "\n",
    "def predict_with_targs(model, dl, flip=True):\n",
    "    model.eval()\n",
    "    preds_targs = [(torch.sigmoid(model(xb)).detach().cpu().numpy(), yb.detach().cpu().numpy()) for xb, yb in dl]\n",
    "    preds, targs = list(zip(*preds_targs))\n",
    "    preds, targs = np.concatenate(preds), np.concatenate(targs)\n",
    "    if not flip: return preds\n",
    "    flipped_preds = np.concatenate([torch.sigmoid(model(torch.flip(xb, [3]))).detach().cpu().numpy() for xb, yb in dl])\n",
    "    preds = (preds + flipped_preds[:,:,::-1]) / 2\n",
    "    return preds, targs\n",
    "\n",
    "def accuracy_np(preds, targs): return np.mean((preds > 0.5) == targs)\n",
    "\n",
    "# https://www.kaggle.com/divrikwicky/u-net-with-simple-resnet-blocks-forked\n",
    "iou_thresholds = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n",
    "\n",
    "def iou(img_true, img_pred):\n",
    "    i = np.sum((img_true*img_pred) >0)\n",
    "    u = np.sum((img_true + img_pred) >0)\n",
    "    if u == 0:\n",
    "        return u\n",
    "    return i/u\n",
    "\n",
    "def iou_metric(imgs_true, imgs_pred):\n",
    "    num_images = len(imgs_true)\n",
    "    scores = np.zeros(num_images)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        if imgs_true[i].sum() == imgs_pred[i].sum() == 0:\n",
    "            scores[i] = 1\n",
    "        else:\n",
    "            scores[i] = (iou_thresholds <= iou(imgs_true[i], imgs_pred[i])).mean()\n",
    "            \n",
    "    return scores.mean()\n",
    "\n",
    "def filter_image(img, mask_t=100):\n",
    "    if img.sum() < mask_t:\n",
    "        return np.zeros(img.shape)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "# https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten(order='F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# def rle_encode(im):\n",
    "#     pixels = im.flatten(order='F')\n",
    "#     pixels = np.concatenate([[0], pixels, [0]])\n",
    "#     runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "#     runs[1::2] -= runs[::2]\n",
    "#     return ' '.join(str(x) for x in runs)\n",
    "\n",
    " \n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "def preds_to_sub(preds, paths, sig_t, mask_t, name):\n",
    "    fns = []\n",
    "    rles = []\n",
    "    for path, pred in zip(paths, preds):\n",
    "        pred = pred > sig_t\n",
    "        pred = filter_image(pred, mask_t)\n",
    "        fns.append(path.stem)\n",
    "\n",
    "        resized = skimage.transform.resize(pred.astype(np.uint8) * 255, (101, 101), order=0, mode='constant', anti_aliasing=False)\n",
    "        rles.append(rle_encode(resized))\n",
    "    pd.DataFrame(data={'id': fns, 'rle_mask': rles}).to_csv(f'../subs/{name}.csv.gz', compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
