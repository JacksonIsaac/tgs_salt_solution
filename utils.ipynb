{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "import albumentations\n",
    "import pretrainedmodels\n",
    "from IPython.core.debugger import set_trace\n",
    "from tqdm import tqdm_notebook\n",
    "import skimage\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pretrainedmodels\n",
    "import lovasz_losses as L\n",
    "from torch.nn.functional import interpolate\n",
    "from layers import *\n",
    "from itertools import chain\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = Path('../data')\n",
    "TRAIN_DN = 'train'\n",
    "TEST_DN = 'test'\n",
    "IMAGES = 'images'\n",
    "MASKS = 'masks'\n",
    "\n",
    "DEPTHS_FN = 'depths.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_means, imagenet_std = map(np.array, ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "ds_means, ds_std = map(np.array, ([0.467, 0.467, 0.467], [0.163, 0.163, 0.163]))\n",
    "\n",
    "# normalize = lambda x: (x - imagenet_means) / imagenet_std\n",
    "# denormalize = lambda x: x * imagenet_std + imagenet_means\n",
    "normalize = lambda x: (x - ds_means * 255) / (ds_std * 255)\n",
    "denormalize = lambda x: x * ds_std + ds_means\n",
    "\n",
    "def open_image(fn):\n",
    "    x = PIL.Image.open(fn).convert('RGB')\n",
    "    return np.asarray(x)\n",
    "\n",
    "def open_mask(fn):\n",
    "    x = PIL.Image.open(fn)\n",
    "    return np.asarray(x) / 65535\n",
    "\n",
    "def show_image(im, figsize=None, ax=None, alpha=None):\n",
    "    if im.shape[0] == 3: im = im.transpose(1,2,0)\n",
    "    if im.min() < 0 and im.ndim == 3: im=denormalize(im); im = np.clip(im, 0, 1) # this is quite horrible and can lead to bugs\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax\n",
    "\n",
    "class FilesDataset(DatasetBase):\n",
    "    def __init__(self, folder, sz, take_idxs=None, tfms=None, img_dir_name='images'):\n",
    "        sub_folders = list(p.stem for p in (folder/str(sz)).iterdir())\n",
    "        self.x = list((folder/str(sz)/img_dir_name).iterdir())\n",
    "        if take_idxs is not None:\n",
    "            self.x = [self.x[idx] for idx in take_idxs]\n",
    "        if img_dir_name == 'images':\n",
    "            if 'masks' in sub_folders:\n",
    "                self.y = list((folder/str(sz)/'masks').iterdir())\n",
    "                if take_idxs is not None:\n",
    "                    self.y = [self.y[idx] for idx in take_idxs]\n",
    "                assert np.all([p1.stem == p2.stem for p1, p2 in zip(self.x, self.y)]) and len(self.x) == len(self.y), \\\n",
    "                    'filenames between self.x and self.y do not match'\n",
    "        self.tfms = tfms\n",
    "            \n",
    "    def __getitem__(self,i):\n",
    "        im = open_image(self.x[i])\n",
    "        if hasattr(self, 'y'):\n",
    "            mask = open_mask(self.y[i])\n",
    "        else:\n",
    "            mask = np.zeros_like(im)[:, :, 0]\n",
    "        if self.tfms is not None:\n",
    "            transformed = self.tfms(image=im, mask=mask)\n",
    "            im, mask = transformed['image'], transformed['mask']\n",
    "        im = normalize(im)\n",
    "        im = im.transpose(2, 0, 1)\n",
    "        im, mask = map(lambda x: x.astype(np.float32), [im, mask])\n",
    "        return im, mask\n",
    "    \n",
    "    def show_im_with_mask(self, idx, axes=None):\n",
    "        im, mask = self[idx]\n",
    "        if axes is None: _, axes = plt.subplots(1, 2)\n",
    "        show_image(im, ax=axes[0])\n",
    "        show_image(mask, ax=axes[1])\n",
    "        \n",
    "    def check_tfms(self, idx, n=5, figsize=(10,4)):\n",
    "        _, axes = plt.subplots(2, n, figsize=figsize)\n",
    "        for i in range(n):\n",
    "            self.show_im_with_mask(idx, axes=(axes[0][i], axes[1][i]))\n",
    "\n",
    "n = len(list((PATH/TRAIN_DN/'128/images').iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagenet_means, imagenet_std = map(np.array, ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "# ds_means, ds_std = map(np.array, ([0.467, 0.467, 0.467], [0.163, 0.163, 0.163]))\n",
    "\n",
    "# # normalize = lambda x: (x - imagenet_means) / imagenet_std\n",
    "# # denormalize = lambda x: x * imagenet_std + imagenet_means\n",
    "# normalize = lambda x: (x - ds_means) / ds_std\n",
    "# denormalize = lambda x: x * ds_std + ds_means\n",
    "\n",
    "# def open_image(fn):\n",
    "#     x = PIL.Image.open(fn).convert('RGB')\n",
    "#     return normalize(np.asarray(x) / 255)\n",
    "\n",
    "# def open_mask(fn):\n",
    "#     x = PIL.Image.open(fn)\n",
    "#     return np.asarray(x) / 65535\n",
    "\n",
    "# def show_image(im, figsize=None, ax=None, alpha=None):\n",
    "#     if im.shape[0] == 3: im = im.transpose(1,2,0)\n",
    "#     if im.min() < 0 and im.ndim == 3: im=denormalize(im); im = np.clip(im, 0, 1) # this is quite horrible and can lead to bugs\n",
    "#     if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "#     ax.imshow(im, alpha=alpha)\n",
    "#     ax.set_axis_off()\n",
    "#     return ax\n",
    "\n",
    "# class FilesDataset(DatasetBase):\n",
    "#     def __init__(self, folder, sz, take_idxs=None, tfms=None):\n",
    "#         sub_folders = list(p.stem for p in (folder/str(sz)).iterdir())\n",
    "#         self.x = list((folder/str(sz)/'images').iterdir())\n",
    "#         if take_idxs is not None:\n",
    "#             self.x = [self.x[idx] for idx in take_idxs]\n",
    "#         if 'masks' in sub_folders:\n",
    "#             self.y = list((folder/str(sz)/'masks').iterdir())\n",
    "#             if take_idxs is not None:\n",
    "#                 self.y = [self.y[idx] for idx in take_idxs]\n",
    "#             assert np.all([p1.stem == p2.stem for p1, p2 in zip(self.x, self.y)]) and len(self.x) == len(self.y), \\\n",
    "#                 'filenames between self.x and self.y do not match'\n",
    "#         self.tfms = tfms\n",
    "            \n",
    "#     def __getitem__(self,i):\n",
    "#         im = open_image(self.x[i])\n",
    "#         if hasattr(self, 'y'):\n",
    "#             mask = open_mask(self.y[i])\n",
    "#         else:\n",
    "#             mask = np.zeros_like(im)[0]\n",
    "#         if self.tfms is not None:\n",
    "#             transformed = self.tfms(image=im, mask=mask)\n",
    "#             im, mask = transformed['image'], transformed['mask']        \n",
    "#         im = im.transpose(2, 0, 1)\n",
    "#         im, mask = map(lambda x: x.astype(np.float32), [im, mask])\n",
    "#         # add depth info here\n",
    "#         return im, mask\n",
    "    \n",
    "#     def show_im_with_mask(self, idx, axes=None):\n",
    "#         im, mask = self[idx]\n",
    "#         if axes is None: _, axes = plt.subplots(1, 2)\n",
    "#         show_image(im, ax=axes[0])\n",
    "#         show_image(mask, ax=axes[1])\n",
    "        \n",
    "#     def check_tfms(self, idx, n=5, figsize=(10,4)):\n",
    "#         _, axes = plt.subplots(2, n, figsize=figsize)\n",
    "#         for i in range(n):\n",
    "#             self.show_im_with_mask(idx, axes=(axes[0][i], axes[1][i]))\n",
    "\n",
    "# n = len(list((PATH/TRAIN_DN/'128/images').iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_sizes = {}\n",
    "# for p in (PATH/TRAIN_DN/'128/masks').iterdir():\n",
    "#     img = PIL.Image.open(p)\n",
    "#     mask_sizes[p.stem] = np.sum(np.asarray(img) != 0)\n",
    "\n",
    "# pd.to_pickle(mask_sizes, PATH/'mask_sizes.pkl')\n",
    "\n",
    "# mask_sizes = pd.read_pickle(PATH/'mask_sizes.pkl')\n",
    "\n",
    "# depths = pd.read_csv(PATH/DEPTHS_FN)\n",
    "# depths.set_index('id',drop=True, inplace=True)\n",
    "# depths = depths.to_dict()['z']\n",
    "\n",
    "# fns = [p.stem for p in (PATH/TRAIN_DN/'128/images').iterdir()]\n",
    "# trn_df = pd.DataFrame(data={'fn': fns})\n",
    "# trn_df['coverage'] = trn_df['fn'].apply(lambda x: mask_sizes[x])\n",
    "# trn_df.coverage /= trn_df.coverage.max()\n",
    "\n",
    "# def cov_class(v):\n",
    "#     for i in range(9, -1, -1):\n",
    "#         if v * 10 >= i: return i\n",
    "\n",
    "# trn_df['cov_class'] = trn_df.coverage.apply(lambda x: cov_class(x))\n",
    "\n",
    "# trn_df.to_csv(PATH/'trn_df_with_cov.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_df = pd.read_csv(PATH/'trn_df_with_cov.csv')\n",
    "# depths = pd.read_csv(PATH/DEPTHS_FN)\n",
    "# quantiles = depths.quantile([0.25, 0.5, 0.75]).z.values\n",
    "\n",
    "# depths['z_q'] = 0\n",
    "# for i, q in enumerate(quantiles):\n",
    "#     depths.loc[depths['z'] > q, 'z_q'] = i + 1\n",
    "    \n",
    "# trn_df = trn_df.merge(depths[['id', 'z_q']], 'left', left_on='fn', right_on='id')\n",
    "# trn_df['class'] = trn_df.cov_class + 10 * trn_df.z_q\n",
    "# trn_df.drop(columns=['cov_class', 'z_q', 'id', 'coverage'], inplace=True)\n",
    "\n",
    "# trn_df.to_csv(PATH/'trn_df_with_class.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "random_state = 0\n",
    "\n",
    "trn_df = pd.read_csv(PATH/'trn_df_with_class.csv')\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "parts = list(skf.split(np.zeros(n), trn_df['class']))\n",
    "\n",
    "val_parts = [parts[i][1] for i in range(n_splits)]\n",
    "trn_parts = [parts[i][0] for i in range(n_splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass()\n",
    "class DataBunch():\n",
    "    train_dl:DataLoader\n",
    "    valid_dl:DataLoader\n",
    "    test_dl:DataLoader\n",
    "    device:torch.device=None\n",
    "    path:Path=PATH\n",
    "\n",
    "def accuracy_thresh(out, yb, thresh=0.5):\n",
    "    preds = torch.sigmoid(out) > thresh\n",
    "    return (preds==yb.byte()).float().mean()\n",
    "\n",
    "def dice(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    return 2. * (pred*targs).sum() / (pred+targs).sum()\n",
    "\n",
    "def accuracy_np(preds, targs): return np.mean((preds > 0.5) == targs)\n",
    "\n",
    "# https://www.kaggle.com/divrikwicky/u-net-with-simple-resnet-blocks-forked\n",
    "iou_thresholds = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n",
    "\n",
    "def iou(img_true, img_pred):\n",
    "    i = np.sum((img_true*img_pred) >0)\n",
    "    u = np.sum((img_true + img_pred) >0)\n",
    "    if u == 0:\n",
    "        return u\n",
    "    return i/u\n",
    "\n",
    "def iou_metric(imgs_true, imgs_pred):\n",
    "    num_images = len(imgs_true)\n",
    "    scores = np.zeros(num_images)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        if imgs_true[i].sum() == imgs_pred[i].sum() == 0:\n",
    "            scores[i] = 1\n",
    "        else:\n",
    "            scores[i] = (iou_thresholds <= iou(imgs_true[i], imgs_pred[i])).mean()\n",
    "            \n",
    "    return scores.mean()\n",
    "\n",
    "def filter_image(img, mask_t=100):\n",
    "    if img.sum() < mask_t:\n",
    "        return np.zeros(img.shape)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "# https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten(order='F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    " \n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_bunch(sz=128, bs=64, part=0, trn_tfms=None):\n",
    "    trn_ds = FilesDataset(PATH/TRAIN_DN, sz, take_idxs=trn_parts[part], tfms=trn_tfms)\n",
    "    val_ds = FilesDataset(PATH/TRAIN_DN, sz, take_idxs=val_parts[part])\n",
    "    tst_ds = FilesDataset(PATH/TEST_DN, sz)\n",
    "    \n",
    "    trn_dl = DataLoader(trn_ds, bs, True, num_workers=11, pin_memory=True)\n",
    "    val_dl = DataLoader(val_ds, bs, False, num_workers=11, pin_memory=True)\n",
    "    tst_dl = DataLoader(tst_ds, bs, False, num_workers=11, pin_memory=True)\n",
    "    \n",
    "    trn_dl, val_dl, tst_dl = map(lambda ts: DeviceDataLoader(*ts), zip([trn_dl, val_dl, tst_dl], [default_device] * 3) )\n",
    "    return DataBunch(trn_dl, val_dl, tst_dl, default_device)\n",
    "\n",
    "def predict_with_TTA(model, dl, upside_down=False):\n",
    "    model.eval()\n",
    "    \n",
    "    preds = np.concatenate([torch.sigmoid(model(xb)).detach().cpu().numpy() for xb, yb in dl])\n",
    "    if upside_down: preds_upside_down = np.concatenate([torch.sigmoid(model(torch.flip(xb, [2]))).detach().cpu().numpy() for xb, yb in dl])\n",
    "    \n",
    "    flipped_preds = np.concatenate([torch.sigmoid(model(torch.flip(xb, [3]))).detach().cpu().numpy() for xb, yb in dl])\n",
    "    if upside_down: flipped_preds_upside_down = np.concatenate([torch.sigmoid(model(torch.flip(xb, [1, 3]))).detach().cpu().numpy() for xb, yb in dl])\n",
    "    \n",
    "    preds = (preds + flipped_preds[:,:,::-1]) / 2\n",
    "    if upside_down: preds = 0.5 * preds + (preds_upside_down[:,::-1,:] + flipped_preds_upside_down[:,::-1,::-1]) / 4 \n",
    "    return preds\n",
    "\n",
    "def predict_with_targs_and_TTA(model, dl, upside_down=False):\n",
    "    preds = predict_with_TTA(model, dl, upside_down)\n",
    "    targs = np.concatenate([yb.detach().cpu().numpy() for xb, yb in dl])\n",
    "    return preds, targs\n",
    "\n",
    "def preds_to_sub(preds, paths, sig_t, mask_t, name):\n",
    "    fns = []\n",
    "    rles = []\n",
    "    for path, pred in zip(paths, preds):\n",
    "        pred = pred > sig_t\n",
    "        pred = filter_image(pred, mask_t)\n",
    "        fns.append(path.stem)\n",
    "\n",
    "#         resized = skimage.transform.resize(pred.astype(np.uint8) * 255, (101, 101), order=0, mode='constant', anti_aliasing=False, preserve_range=True)\n",
    "        resized = skimage.transform.resize(pred, (101, 101), order=1, mode='constant', anti_aliasing=False, preserve_range=True) > 0.5\n",
    "        rles.append(rle_encode(resized))\n",
    "    pd.DataFrame(data={'id': fns, 'rle_mask': rles}).to_csv(f'../subs/{name}.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss(preds, targs): return F.binary_cross_entropy_with_logits(preds, targs)\n",
    "def lovasz_loss(preds, targs): return L.lovasz_hinge(preds, targs)\n",
    "\n",
    "def iou_pytorch(out, yb):\n",
    "    preds = out > 0\n",
    "    return torch.tensor(iou_metric(yb.cpu().numpy(), preds.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaningfully_greater(a, b, delta = 1e-3):\n",
    "    return a - b > delta\n",
    "\n",
    "class SaveBest(Callback):\n",
    "    def __init__(self):\n",
    "        self.iou = 0\n",
    "    def on_epoch_end(self, epoch, num_batch, smooth_loss, last_metrics, **kwargs): \n",
    "        iou = last_metrics[-1]\n",
    "        if iou > self.iou:\n",
    "            self.iou = iou\n",
    "            learn.save(f'{name}_best_iou_fold{fold}')\n",
    "            \n",
    "class ReduceLROnPlateau(Callback):\n",
    "    def __init__(self, learn, patience=5, div_factor=10, grace=0):\n",
    "        self.learn = learn\n",
    "        self.patience = patience\n",
    "        self.div_factor = div_factor\n",
    "        \n",
    "        self.iou = 0\n",
    "        self.epochs_without_improv = 0\n",
    "        self.grace = grace # number of epochs to remain inactive after train start\n",
    "                           # useful for retraining starting with higher lr\n",
    "    def on_epoch_end(self, epoch, num_batch, smooth_loss, last_metrics, **kwargs): \n",
    "        if self.grace > 0:\n",
    "            self.grace -= 1\n",
    "            return\n",
    "        \n",
    "        iou = last_metrics[-1]\n",
    "        if meaningfully_greater(iou, self.iou):\n",
    "            self.epochs_without_improv = 0\n",
    "            self.iou = iou\n",
    "        else:\n",
    "            self.epochs_without_improv += 1\n",
    "        if self.epochs_without_improv == self.patience:\n",
    "            lr = self.learn.opt.read_val('lr')\n",
    "            self.learn.opt.lr = np.array(lr) / self.div_factor\n",
    "            print(f'Reducing lr to: {self.learn.opt.lr}')\n",
    "            self.epochs_without_improv = 0\n",
    "            \n",
    "    \n",
    "class StopTrain(Callback):\n",
    "    def __init__(self, learn, patience=5):\n",
    "        self.learn = learn\n",
    "        self.patience = patience\n",
    "        \n",
    "        self.iou = 0\n",
    "        self.epochs_without_improv = 0\n",
    "    def on_epoch_end(self, epoch, num_batch, smooth_loss, last_metrics, **kwargs): \n",
    "        iou = last_metrics[-1]\n",
    "        if meaningfully_greater(iou, self.iou):\n",
    "            self.epochs_without_improv = 0\n",
    "            self.iou = iou\n",
    "        else:\n",
    "            self.epochs_without_improv += 1\n",
    "        if self.epochs_without_improv == self.patience:\n",
    "            lr = self.learn.opt.read_val('lr')\n",
    "            print(f'Finishing training with lr: {lr}')\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_preds_t(val_preds, val_targs):\n",
    "    res = []\n",
    "    ts = np.linspace(0.3, 0.7, 21)\n",
    "    for t in ts:\n",
    "        res.append(iou_metric(val_targs, val_preds > t))\n",
    "    return ts[np.argmax(res)]\n",
    "\n",
    "def normalize_t(val_preds, val_targs, test_preds):\n",
    "    best_t = best_preds_t(val_preds, val_targs)\n",
    "    \n",
    "    val_preds += 0.5 - best_t\n",
    "    val_preds = np.clip(val_preds, 0, 1)\n",
    "    \n",
    "    test_preds += 0.5 - best_t\n",
    "    test_preds = np.clip(test_preds, 0, 1)\n",
    "    \n",
    "    return val_preds, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
